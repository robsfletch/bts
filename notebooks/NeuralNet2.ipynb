{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "global-recruitment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rsfletch/github/bts/notebooks'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import load_model\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "quick-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df):\n",
    "    # 'HPG', 'HPAB_p', 'spot', 'home', 'factor', 'BAT_HAND', 'PIT_HAND', 'avg_win', 'year'\n",
    "    cols = [\n",
    "        'spot', 'home', 'b_HPG', 'p_HPAB', 'park_factor', 'year',\n",
    "        'BAT_HAND', 'PIT_HAND', 'b_avg_win', 'p_team_HPAB',\n",
    "        'p_avg_game_score', 'p_team_avg_game_score'\n",
    "    ]\n",
    "    num_cols = len(cols)\n",
    "    num_feat = num_cols - 1\n",
    "    \n",
    "    \n",
    "    df[['home']] = df[['home']]*1\n",
    "    X = df[cols]*1\n",
    "    Y = df[['Win']]*1\n",
    "    X_train = X[(df.year >= 2000) & (df.year < 2010)].to_numpy().astype('float') # (df.year >= 2000) & \n",
    "    Y_train = Y[(df.year >= 2000) & (df.year < 2010)].to_numpy().astype('float') # (df.year >= 2000) & \n",
    "    X_test = X[df.year >=  2010].to_numpy().astype('float')\n",
    "    Y_test = Y[df.year >=  2010].to_numpy().astype('float')\n",
    "\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    X_train -= mean\n",
    "    X_test -= mean\n",
    "    std = np.std(X_train, axis=0)\n",
    "    print(std)\n",
    "    X_train /= std\n",
    "    X_test /= std\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dynamic-learning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.50616573 0.49999972 0.25387502 0.03705335 0.07224307 2.8330341\n",
      " 0.49354651 0.4464489  0.11226924 0.03653893 5.29353691 5.31655443]\n"
     ]
    }
   ],
   "source": [
    "processed = '../data/processed'\n",
    "main_data = pd.read_pickle(Path(processed) / 'main_data.pkl')\n",
    "\n",
    "main_data = main_data.dropna()\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = prep_data(main_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "tamil-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=12, activation='relu'))\n",
    "model.add(Dense(18, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "provincial-simon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "295714/295714 [==============================] - 15s 49us/step - loss: 0.6316 - auc_9: 0.5772\n",
      "Epoch 2/30\n",
      "295714/295714 [==============================] - 14s 47us/step - loss: 0.6275 - auc_9: 0.5870\n",
      "Epoch 3/30\n",
      "295714/295714 [==============================] - 15s 50us/step - loss: 0.6270 - auc_9: 0.5886\n",
      "Epoch 4/30\n",
      "295714/295714 [==============================] - 14s 48us/step - loss: 0.6268 - auc_9: 0.5892\n",
      "Epoch 5/30\n",
      "295714/295714 [==============================] - 14s 47us/step - loss: 0.6266 - auc_9: 0.5899\n",
      "Epoch 6/30\n",
      "295714/295714 [==============================] - 13s 45us/step - loss: 0.6265 - auc_9: 0.5901\n",
      "Epoch 7/30\n",
      "295714/295714 [==============================] - 14s 48us/step - loss: 0.6265 - auc_9: 0.5902\n",
      "Epoch 8/30\n",
      "295714/295714 [==============================] - 14s 48us/step - loss: 0.6264 - auc_9: 0.5905\n",
      "Epoch 9/30\n",
      "295714/295714 [==============================] - 14s 46us/step - loss: 0.6264 - auc_9: 0.5903\n",
      "Epoch 10/30\n",
      "295714/295714 [==============================] - 13s 46us/step - loss: 0.6264 - auc_9: 0.5903\n",
      "Epoch 11/30\n",
      "295714/295714 [==============================] - 13s 45us/step - loss: 0.6263 - auc_9: 0.5908 0s - loss: 0.6263 - auc_9\n",
      "Epoch 12/30\n",
      "295714/295714 [==============================] - 13s 44us/step - loss: 0.6263 - auc_9: 0.5908\n",
      "Epoch 13/30\n",
      "295714/295714 [==============================] - 13s 44us/step - loss: 0.6263 - auc_9: 0.5909\n",
      "Epoch 14/30\n",
      "295714/295714 [==============================] - 13s 44us/step - loss: 0.6263 - auc_9: 0.5908 0s - loss: 0.6263 - au\n",
      "Epoch 15/30\n",
      "295714/295714 [==============================] - 13s 44us/step - loss: 0.6262 - auc_9: 0.5911\n",
      "Epoch 16/30\n",
      "295714/295714 [==============================] - 14s 48us/step - loss: 0.6262 - auc_9: 0.5912\n",
      "Epoch 17/30\n",
      "295714/295714 [==============================] - 14s 46us/step - loss: 0.6262 - auc_9: 0.5914\n",
      "Epoch 18/30\n",
      "295714/295714 [==============================] - 14s 47us/step - loss: 0.6262 - auc_9: 0.5912\n",
      "Epoch 19/30\n",
      "295714/295714 [==============================] - 14s 46us/step - loss: 0.6261 - auc_9: 0.5914\n",
      "Epoch 20/30\n",
      "295714/295714 [==============================] - 13s 45us/step - loss: 0.6261 - auc_9: 0.5913 1s - loss:\n",
      "Epoch 21/30\n",
      "295714/295714 [==============================] - 13s 45us/step - loss: 0.6261 - auc_9: 0.5916\n",
      "Epoch 22/30\n",
      "295714/295714 [==============================] - 14s 47us/step - loss: 0.6261 - auc_9: 0.5916\n",
      "Epoch 23/30\n",
      "295714/295714 [==============================] - 14s 46us/step - loss: 0.6260 - auc_9: 0.5917\n",
      "Epoch 24/30\n",
      "295714/295714 [==============================] - 14s 46us/step - loss: 0.6260 - auc_9: 0.5919\n",
      "Epoch 25/30\n",
      "295714/295714 [==============================] - 14s 46us/step - loss: 0.6260 - auc_9: 0.5916\n",
      "Epoch 26/30\n",
      "295714/295714 [==============================] - 14s 46us/step - loss: 0.6260 - auc_9: 0.5918\n",
      "Epoch 27/30\n",
      "295714/295714 [==============================] - 14s 46us/step - loss: 0.6260 - auc_9: 0.5917\n",
      "Epoch 28/30\n",
      "295714/295714 [==============================] - 13s 46us/step - loss: 0.6260 - auc_9: 0.5918\n",
      "Epoch 29/30\n",
      "295714/295714 [==============================] - 14s 46us/step - loss: 0.6260 - auc_9: 0.5917\n",
      "Epoch 30/30\n",
      "295714/295714 [==============================] - 14s 46us/step - loss: 0.6260 - auc_9: 0.5919 1s - loss: 0.6259 - au - ETA: 0s - loss: 0.6261\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='loss', patience=2)\n",
    "model.fit(X_train, Y_train, epochs=30, batch_size=64, callbacks=[callback])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "level-study",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 18)                234       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 409\n",
      "Trainable params: 409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "312791/312791 [==============================] - 15s 50us/step\n",
      "Accuracy: 58.57\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "_, accuracy = model.evaluate(X_test, Y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "searching-powder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rsfletch/opt/anaconda3/envs/bts/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "test_data = main_data[main_data.year >=  2010]\n",
    "test_data['EstProb'] = predictions\n",
    "test_data = test_data.set_index(['GAME_ID', 'BAT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "three-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = test_data.groupby('Date')['EstProb'].nlargest(2).to_frame()\n",
    "\n",
    "selection = selection.sort_values(\n",
    "    by=['Date', 'EstProb', 'GAME_ID'], ascending=[True, False, True])\n",
    "\n",
    "selection['pick_order'] = selection.groupby(['Date']).cumcount()+1\n",
    "selection.to_pickle('../data/processed/selection_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fatty-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "interim = '../data/interim'\n",
    "processed = '../data/processed'\n",
    "\n",
    "hits = pd.read_pickle(Path(interim) / 'hits.pkl')\n",
    "\n",
    "# selection_data = selections.merge(hits, on =['GAME_ID', 'BAT_ID'])\n",
    "selection_data = selection.merge(main_data, on =['GAME_ID', 'BAT_ID'])\n",
    "selection_data = selection_data.set_index(['Date', 'pick_order'])\n",
    "\n",
    "selection_data.to_pickle(Path(processed) / 'selection_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-sustainability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bts",
   "language": "python",
   "name": "bts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
